# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1u-HS1s0M60076IsG0RDH0c-zdu3D0Ob1
"""

import sklearn.datasets
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

#load the breast cancer data
breast_cancer = sklearn.datasets.load_breast_cancer()

#convert the data to pandas dataframe.
data = pd.DataFrame(breast_cancer.data, columns = breast_cancer.feature_names)
data["class"] = breast_cancer.target
data.head()

data.describe()

print(data['class'].value_counts())

#plotting a graph to see class imbalance
data['class'].value_counts().plot(kind = "barh")
plt.xlabel("Count")
plt.ylabel("Classes")
plt.show()

print(breast_cancer.target_names)
print(breast_cancer.feature_names)

X = data.drop("class", axis = 1)
X = data[['mean radius','mean texture','mean perimeter','mean area','mean smoothness','mean compactness','mean concavity','mean concave points','mean symmetry','mean fractal dimension','radius error','texture error','perimeter error','area error','smoothness error','compactness error','concavity error','concave points error','symmetry error','fractal dimension error','worst radius','worst texture','worst perimeter','worst area','worst smoothness','worst compactness','worst concavity','worst concave points','worst symmetry','worst fractal dimension']].values
Y = data[["class"]].values
#print(X,Y)

#train test split.
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.1, stratify = Y, random_state = 1)

X_train.shape, Y_train.shape

# create NeuralNetwork class
class NeuralNetwork:

    # intialize variables in class
    def __init__(self, inputs, outputs):
        self.inputs  = inputs
        self.outputs = outputs
        # initialize weights as .50 for simplicity
        np.random.seed(0)
        #self.weights = np.array([[.50], [.50], [.50]])
        self.weights = np.random.rand(X.shape[1],1)
        self.bias = np.random.rand(1)
        self.error_history = []
        self.epoch_list = []

    #activation function ==> S(x) = 1/1+e^(-x)
    def sigmoid(self, x, deriv=False):
        if deriv == True:
            return self.sigmoid(x) * (1 - self.sigmoid(x))
        return 1 / (1 + np.exp(-x))

    def threshold(self,x):
      if(x>=0.5):
        return 1
      else:
        return 0

    # data will flow through the neural network.
    def feed_forward(self):
        self.yCap = self.sigmoid(np.dot(self.inputs, self.weights))

    # going backwards through the network to update weights
    def backpropagation(self):
        self.error  = self.outputs - self.yCap
        self.lr = 0.5
        delta = self.error * self.sigmoid(self.yCap, deriv=True)
        self.weights += np.dot(self.inputs.T, delta)*self.lr
        for num in delta:
              self.bias -= self.lr * num

    # train the neural net for 25,000 iterations
    def train(self, epochs=14000):
        for epoch in range(epochs):
            # flow forward and produce an output
            self.feed_forward()
            # go back though the network to make corrections based on the output
            self.backpropagation()    
            # keep track of the error history over each epoch
            self.error_history.append(np.average(np.abs(self.error)))
            self.epoch_list.append(epoch)

    # function to predict output on new and unseen input data                               
    def predict(self, new_input):
        prediction = self.sigmoid(np.dot(new_input, self.weights)+self.bias)
        bclass = self.threshold(prediction)
        return (prediction,bclass)
        #return prediction

# create neural network   
NN = NeuralNetwork(X_train, Y_train)
# train neural network
NN.train()

X_test[0]
# create two new examples to predict                                   
#example = X_test[7]
#print('Value: ',NN.predict(example)[0], 'Class:', NN.predict(example)[1] ,' - Correct: ', Y_test[7])
#example = X_test[9]
#print('Value: ',NN.predict(example)[0], 'Class:', NN.predict(example)[1] ,' - Correct: ', Y_test[9])
y_pred = []
#X_test.shape
for i in range(len(X_test)):
  print(i)
  example = X_test[i]
  print('Value: ',NN.predict(example)[0], 'Class:', NN.predict(example)[1] ,' - Correct: ', Y_test[i])
  y_pred.append(NN.predict(example)[1])
#print(list(y_pred),Y_test)

plt.figure(figsize=(15,5))
plt.plot(NN.epoch_list, NN.error_history)
plt.xlabel('Epoch')
plt.ylabel('Error')
plt.show()

from sklearn.metrics import accuracy_score
print(accuracy_score(y_pred, Y_test))